# 3장 정리 - 분류

# 1. MNIST

- 숫자 이미지로 구성된 데이터 셋을 말함 (0~9)
- 각 이미지에는 어떤 숫자를 나타내는지 label되어있음
- 데이터 셋들의 딕셔너리 구조
    - 데이터셋을 설명하는 DESCR키
    - 샘플이 하나의 행, 특성이 하나의 열로 구성된 배열을 가진 data키
    - label 배열을 담은 target키
    
    ![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20-%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%2045aa7cba4a894b17b949ea013304ce5a/Untitled.png)
    
    ![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20-%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%2045aa7cba4a894b17b949ea013304ce5a/Untitled%201.png)
    

# 2. 이진 분류기 훈련

### 이진분류기

- 두개의 클래스를 구분할 수 있는 분류기로 맞는지 아닌지만을 구분
- EX) 숫자 5를 식변한다하면 ‘5’와 ‘5 아님’ 두 클래스를 구분
    - 5를 가리키는 이미지 label: 1
    - 5이외의 수를 가리키는 이미지 label: 0

### SGD 분류기 활용 학습

- SGDClassifier 모델을 만들고 전체 훈련 세트를 사용해 훈련
- 확률적 경사 하강법 분류기: 매우 큰 데이터셋을 효율적으로 처리하는 장점을 가짐
- 한번에 하나씩 훈련 샘플 처리 후 파라미터 조정
- 매우 큰 데이터 셋 처리에 효율적이며 온라인 학습에도 적합

### 목적에 따라 다르게 결정

- 문제 구성, 알고리즘 선택, 모델 평가와 성능 지표, 모델 튜닝시에 리소스 결정

# 3. 성능 측정

- 분류기 평가는 회귀 모델보다 어려움

## 교차 검증을 사용한 정확도 측정

- cross_val_score() 함수로 fold가 3개인 k-겹 교차 검증을 사용해 SGDClassifier 모델 평가
- 성능 측정 기준 : 정확도
- 교차 검증을 사용한 정확도 측정 - **StratifiedKFold** 클래스 (계층적 샘플링수행)

```python
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone

skfolds = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)

for train_index, test_index in skfolds.split(X_train, y_train_5):
    clone_clf = clone(sgd_clf)
    X_train_folds = X_train[train_index]
    y_train_folds = y_train_5[train_index]
    X_test_fold = X_train[test_index]
    y_test_fold = y_train_5[test_index]

    clone_clf.fit(X_train_folds, y_train_folds)
    y_pred = clone_clf.predict(X_test_fold)
    n_correct = sum(y_pred == y_test_fold)
    print(n_correct / len(y_pred))

never_5_clf = Never5Classifier()
cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring="accuracy")
```

- 더미 분류기 - 모든 이미지를 ‘5아님’으로 분류
- **정확도가 분류기의 성능 측정 지표로써 적절하지 않음을 보여줌**

```python
from sklearn.base import BaseEstimator
class Never5Classifier(BaseEstimator):
    def fit(self, X, y=None):
        pass
    def predict(self, X):
        return np.zeros((len(X), 1), dtype=bool)
```

## 정밀도 & 재현율 조율

### 오차 행렬

- 위에 교차검증보다 분류기의 성능을 평가하는 더 좋은 방법
- 클래스 A의 샘플이 클래스 B로 분류된 횟수를 세는 것
- 실제 타깃과 비교할 수 있도록 먼저 예측값 작성
    - **cross_val_predict()** 를 이용 - 훈련 세트에 있는 모든 샘플의 점수를 구함
- **confusion_matrix() -** 함수를 사용해 오차 행렬 생성

```python
from sklearn.model_selection import **cross_val_predict**
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)

from sklearn.metrics import **confusion_matrix**
confusion_matrix(y_train_5, y_train_pred)
```

- 오차 행렬의 요약된 지표
    - **정밀도** = 양성 예측의 정확도
    - **재현율** = 진짜 양성 비율 또는 민감도
- 정밀도는 재현율과 같이 일반적으로 사용됨

### 조화 평균

- 정밀도와 재현율을 **F1 점수**라고 하는 하나의 숫자로 만듬
- **F1 점수는 재현율과 정밀도의 조화평균임**
- 상황에 따라 정밀도가 중요할 수도 있고 재현율이 중요할 수도 있음

### 트레이드오프

- 정밀도를 올리면 재현율이 줄고 그 반대도 마찬가지 - 이를 트레이드 오프라고 함
- 결정 임곗값 - 샘플의 점수가 임곗값보다 크면 양성 클래스에 할당하고 그렇지 않으면 음성 클래스에 할당
    - 결정 함수 (decision function) 을 사용하여 각 샘플의 점수를 계산함
- 여러 가지 임곗값 - 임곗값 조절에 따라 정밀도와 재현율의 비율이 변화됨.

## ROC 곡선과 AUC 측정

### ROC 곡선

- 수신기 조작 특성(ROC) 곡선도 이진 분류에서 널리 사용
- 정의 - **거짓 양성 비율 (FPR)에 대한 진짜 양성 비율(TPR)의 곡선**
- FPR - 양성으로 잘못 분류된 음성 샘플의 비율 (FPR = 1 - TNR)
- TPR - 진짜 양성 비율 (재현율)
- TNR - 특이도 (진짜 음성 비율)

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20-%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%2045aa7cba4a894b17b949ea013304ce5a/Untitled%202.png)

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20-%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%2045aa7cba4a894b17b949ea013304ce5a/Untitled%203.png)

- ROC 곡선은 민감도 (재현율)에 대한 1 - 특이도 그래프

```python
from sklearn.metrics import roc_curve
fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)
```

### AUC(곡선 아래의 면적) 측정

- AUC: ROC 곡선 아래의 면적
    - 1에 가까울 수록 성능이 좋다고 평가
- 진짜 양성 비율(TPR)과 거짓양성비율(FPR) 사이에 트레이드오프가 있음
    - TPR이 높을 수록 분류기가 만드는 FPR이 증가함
- 좋은 분류기는 TPR은 높으면서 FPR 비율은 최대한 낮게 유지
- ROC 곡선이 y축에 최대한 근접하는 결과가 나오도록 해야함

 

```python
# SGD와 랜덤 포레스트의 AUC 비교
from sklearn.ensemble import RandomForestClassifier
forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)
y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,
                                    method="predict_proba")

roc_auc_score(y_train_5, y_scores_forest)

y_train_pred_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3)
precision_score(y_train_5, y_train_pred_forest)

# AUC 점수
recall_score(y_train_5, y_train_pred_forest)
```

# 4. 다중 분류

- 3개 이상의 클래스로 샘플을 분류하며 다항 분류기라고도 불림
- **다중 분류 지원 분류기**
    - SGD 분류기, 랜덤 포레스트 분류기, 나이브 베이즈 분류기
- **이진 분류만 지원하는 분류기**
    - 로지스틱 회귀, 서포트  벡터 머신 분류기
- **이진 분류기를 여러 개 사용**해 다중 클래스를 분류하는 기법
    - 일대다 방식 - OvR 전략, OvA 전략
    - 일대일 방식 - OvO 전략
        - 클래스가 N개면 분류기는 N X (N - 1) / 2개 필요함

## 일대일 방식 - OvO 전략

- 조합 가능한 모든 일대일 분류 방식을 진행하여 가장 많은 결투를 이긴 숫자를 선택
    - ex) 0과 1, 0과 2, 1과 2 이런식으로
- 클래스가 N개라면 분류기는 N X (N - 1) / 2개가 필요함
    - 위에 MNIST 문제(0~9 이미지 구별)에서는 (10x9)/2=45 개의 분류기를 훈련 시켜야함
    - 45개의 분류기를 모두 통과시켜서 가장 많이 양성으로 분류된 클래스를 선택
- **장점**: 각 분류기의 훈련에 전체 훈련 세트 중 구별할 두 클래스의 샘플만 필요

```python
**sklearn의 SVM 분류기 테스트 (SVM같은 일부 알고리즘은 OvO 선호)
-> 하지만 대부분의 이진 분류 알고리즘에서는 OvR을 선호**
from sklearn.svm import SVC

svm_clf = SVC(gamma="auto", random_state=42)
svm_clf.fit(X_train[:1000], y_train[:1000]) # y_train_5이 아니라 y_train입니다
svm_clf.predict([some_digit])

샘플당 10개의 점수를 반환
some_digit_scores = svm_clf.decision_function([some_digit])
some_digit_scores
```

## 일대다 방식 - OvR 혹은 OvA

- 이미지를 분류할 때 각 분류기의 결정 점수 중에서 가장 높은 것을 클래스로 선택
- 이진 분류 알고리즘을 사용하면 자동으로 알고리즘에 따라 OvO 혹은 OvR을 실행한다
    - OvR을 강제 하려면 **OneVsOneClassifier**를 사용한다

```python
# SVC를 기반으로 OvR 전략을 사용하는 분류기
from sklearn.multiclass import **OneVsRestClassifier**
ovr_clf = OneVsRestClassifier(SVC(gamma="auto", random_state=42))
ovr_clf.fit(X_train[:1000], y_train[:1000])
ovr_clf.predict([some_digit])

# SGDClassifier를 훈련 시키는 코드
sgd_clf.fit(X_train, y_train)
sgd_clf.predict([some_digit])

sgd_clf.decision_function([some_digit])
```

# 5. 에러 분석

- 가능성이 높은 모델을 하나 찾았다고 가정하고 이 모델의 성능을 향상시킬 방법을 모색
    
    ⇒ 그 방법중 하나는 만들어진 에러의 종류를 분석하는 것
    

## 오차 행렬 활용

- 손글씨 클래스 분류 모델의 오차 행렬을 이미지로 표현 가능
    1. cross_val_predict predict함수를 사용해 예측을 만들고 confusion _matrix 함수를 사용함.
    2. 이를 matshow함수를 이용해 이미지로 표현하면 에러를 확인가능
        1. 예를들어 숫자 5는 다른 숫자보다 어두워 보임
            
            → 숫자 5의 이미지가 적거나 숫자 5를 잘 분류하지 못함
            
    3. 오차율 이미지
        - 에러부분에 초점을 맞춤
            
            → 오차 행렬의 각 값을 대응되는 클래스의 이미지 개수로 나누어 에러비율을 비교
            
            → 다른 항목은 그대로 유지하고 주 대각선만 0으로 채워서 그래프를 그린다
            
            → 그러면 여기서 분류기가 만든 에러를 확실히 볼 수 있다
            
        - 이 그래프에서 행을 실제 클래스를 나타내고 열은 예측한 클래스을 나타냄
        
        ![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20-%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%2045aa7cba4a894b17b949ea013304ce5a/Untitled%204.png)
        
        - 클래스 8의 열이 상당히 밝음
            
            → 많은 이미지가 8로 잘못 분류됨
            
            → 하지만 8행은 전반적으로 어두움 (실제 8이 적절히 8로 분류된것을 나타냄)
            
        - (3, 5)와 (5,3)의 위치가 상대적으로 밝음
            
            → 3과 5가 많이 혼동되고 있음을 의미함
            

<aside>
💡 **오차 행렬 분석으로 성능 향상 방안에 대한 통찰을 얻을 수 있음**

</aside>

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20-%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%2045aa7cba4a894b17b949ea013304ce5a/Untitled%205.png)

# 6. 다중 label 분류

- 분류기가 샘플마다 여러 개의 클래스를 출력해야 할 경우 학습
    - 얼굴인식 분류기 - 한 사진에 여러 사람의 얼굴을 인식해야하는 경우
- 여러 개의 이진 꼬리표를 출력하는 분류 시스템을 **다중 레이블 분류 시스템**이라고 함

## 다중 레이블 분류기를 평가하는 방법

- 평가 방법은 다양함 → 적절한지는 프로젝트에 따라 다름
    1. 모든 레이블의 가중치가 같다고 가정: 각레이블의 F1 점수를 구하고 평균 점수를 계산
    2. 가중치: 레이블에 클래스의 **지지도(타깃 레이블에 속한 샘플의 수)**를 가중치로 주기
    - average = “weighted”로 설정

# 7. 다중 출력 분류

- 다중 출력 다중 클래스 분류 (다중 출력 분류)
    - 다중 레이블 분류에서 한 레이블이 다중 클래스가 될 수 있도록 일반화 한것
    - 즉 값을 두개 이상 가질 수 있음
- ex) 이미지에서 잡음을 제거하는 시스템을 만들어보기

![Untitled](3%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20-%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%2045aa7cba4a894b17b949ea013304ce5a/Untitled%206.png)