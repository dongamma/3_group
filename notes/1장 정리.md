# 1장 정리

# 1장

## 머신러닝

- 데이터에서부터 학습하도록 컴퓨터를 프로그래밍하는 과학

## 학습

- 훈련 데이터로부터 가중치 매개변수의 최적값을  자동으로 획득 하는 것

### 학습 - 수학관점

- 베이즈 정리
- 평균제곱오차
- 미분
- 선형대수

### 가중치 매개변수

- 모델이 학습 데이터로 부터 지식을 습득하고 일반화하는데 중요한 역할을 함
- 가중치:  각 신호의 영향력을 조절하는 매개변수
- 편향: 뉴런이 얼마나 쉽게 활성화 하느냐를 조정하는 매개변수

## 머신러닝을 사용하는 이유

- 전통적 프로그래밍 기법으로는 규칙이 점점 길고 복잡해져서 유지보수가 힘듬
- 전통적인 방식으로는 너무 복잡

### 머신 러닝의 장점

- 정리해보자면 복잡하고 어려운 문제에 대해 해답을 찾을 수 있다

## 간단한 머신러닝 사례

- 이미지 분류
- 자연어 처리
- 최귀 분석
- 음성인식
- 이상치 탐지
- 추천 시스템
- 강화 학습

## 머신러닝 시스템의 종류

### 넓은 범주의 분류

- 사람이 감독을 하느냐의 여부
    - **지도 학습** - 알고리즘에 주입하는 훈련 데이터에 label이라는 답이 포함
        - 선형회귀 - 특성을 사용해 타겟 수치 예측
        - k- 최근접이웃
        - 로지스틱 회귀
        - 서포트 벡터 머신
        - 결정트리와 랜덤포레스트
        - 신경망
    - **비지도 학습** - 훈련 데이터에 label이 없어서 시스템이 아무런 도움없이 학습함
        - 군집 (k-means) - 비슷한 특징을 가진 몇 개의 그룹으로 데이터를 나누는 것
        - 계층 군집 분석
        - DBSCAN
        - 이상치 탐지 & 특이치 탐지
        - PCA - 데이터의 특성 수 줄이기
    - **준지도 학습** - 지도학습과 비지도 학습 혼합 사용, 적은수의 샘플에만 label 적용
        - 심층 신뢰 신경망
    - **강화 학습**
        - 학습을 담당하는 에이전트가 수행한 액션에 대해서 환경에서 보상을 받음
        - 가장 큰 보상을 받기 위한 정책을 스스로 학습
        - 정책은 주어진 상황에서 에이전트가 어떤 행동을 선택할 지 정의 함
- 실시간으로 잠진적인 학습을 하는지 여부
    - **배치 학습**
        - 시스템이 점진적으로 학습할 수 없음, 전체 데이터를 모두 사용
    - **온라인 학습**
        - 데이터를 순차적으로 한 개씩 또는 미니배치라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련함
- 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 데이터셋에서 패턴을 발견후 예측모델을 만드는 것인지 차이
    
    → 머신 러닝 시스템의 일반화 방식에 따른 분류
    
    - **사례 기반 학습**
        - 샘플을 기억하는 것으로 학습함
        - 예측을 위해 기존 샘플과의 유사도 측정
    - **모델 기반 학습**
        - 모델을 미리 지정한 후 훈련 세트를 사용하여 모델을 훈련시킴
        - 훈련된 모델을 사용해 새로운 데이터에 대한 예측 실행

### 모델 기반 학습 - 선형 모델

- 데이터를 2차원 그래프에서 점으로 나타내면 어느정도 규칙이 있음

![Untitled](1%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20860b5766edce400da3c1139a72fcd6c2/Untitled.png)

- 이를 대표하는 하나의 직선이 존재 (선형 모델)

![Untitled](1%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20860b5766edce400da3c1139a72fcd6c2/Untitled%201.png)

- 모델이 좋은지를 나타내는 효용함수와 모델이 나쁜지를 나타내는 비용함수를 확인하여 모델의 성능평가를 하여 가장 적합한 모델을 학습

## 머신러닝의 주요 도전과제

- 머신러닝의 주요 작업은 학습 알고리즘을 선택해서 어떤 데이터에 훈련시키는것인데 이때 문제가 되는 과제들이 있다

### 나쁜 데이터

- 충분하지 않은 양
- 대표성이 없음
- 낮은 품질
- 관련이 없는 특성

### 나쁜 알고리즘

- 훈련 데이터 과대 적합 - 훈련 세트에 너무 특화되어 일반화 성능이 떨어지는 현상
- 훈련 데이터 과소 적합 - 모델이 너무 단순해 잘 학습하지 못함 (여러 규제가 많은 경우)

## 테스트와 검증

### 검증

- 훈련된 모델의 성능을 평가하는데 여기엔 테스트 세트를 활용함
- 훈련과 테스트 세트의 비율은 8대 2
- 검증 기준 - 일반화 오차
    - 테스트 세트에서 모델을 평가해 이 오차에 대한 추정값을 얻음
    - 새로운 샘플에 대한 오류 비율
    - 학습된 모델의 일반화 성능의 기준

### 하이퍼파라미터

- 알고리즘 학습 모델 지정에 사용되는 파라미터
- 훈련 과정에 변하는 파라미터가 아님
- 사람이 직접 설정해야하는 매개 변수
- 하이퍼파라미터를 조절하면서 가장 좋은 성능의 모델 선정

### 교차 검증

- **예비표본 검증**
    - 예비표본 - 훈련 세트의 일부로 만들어진 데이터셋
    - 다양한 하이퍼파라미터 값을 후보 모델 평가용으로 예비표본을 검증 세트로 활용하는 기법
- **교차 검증**
    - 여러 개의 검증세트를 사용한 반복적인 예비표본 검증 적용 기법
    - 장점: 교차 검증 후 모든 모델의 평가를 평균하면 훨씬 정확한 성능 측정 가능
    - 단점: 훈련 시간이 검증 세트의 개수에 비례해 늘어남
- **데이터 불일치**
    - 모델 훈련에 사용된 데이터가 실전에 사용되는 데이터를 완벽하게 대변하지 못하는 경우 발생
- **NFL**
    - 주어진 데이터 셋에 가장 적절한 모델을 미리 알 수 없음
    - 다양한 모델과 다양한 하이퍼파라미터 튜닝을 통해 확인해야함